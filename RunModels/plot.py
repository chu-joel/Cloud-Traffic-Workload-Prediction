import seaborn as sns
from matplotlib import pyplot as plt
# training = [0.6144364341193012, 0.008294898340952128, 0.003531746691659562, 0.002890621850208091, 0.0028156060000419643, 0.0027828233352216805, 0.0027481084677901135, 0.0027361562459826383, 0.0027297026953885415, 0.002723302331641237, 0.002739885298148486, 0.0026724614107544774, 0.002667436100711942, 0.0026481151553429797, 0.0026880198050694836, 0.0026998829413826045, 0.0026597363440577946, 0.0026231307118453114, 0.0026265285425612966, 0.0026198290250194203, 0.0025801139258596036, 0.0026107791970654357, 0.002585012259697732, 0.0026127256982377976, 0.0025885772872020468, 0.0026083521808643487, 0.0025809968594051754,
#             0.0025928744410502816, 0.002588806095306556, 0.002612691209039025, 0.002586902581346742, 0.0025806390801181235, 0.0026222646868579603, 0.0027289782981854424, 0.0027253357603584517, 0.0025451641110528847, 0.0025941867181939306, 0.002606363811611162, 0.0026420090913444067, 0.00264054293756218, 0.002801528778973197, 0.002582185108793063, 0.002558232951272001, 0.0025173232951272001, 0.002517371968514382, 0.002583949428446519, 0.00255305479573811, 0.002527646210151901, 0.00250545027004403, 0.0024769951998021037, 0.0025195398957381637]

training = [1.7210403505875707, 0.13750158969350512, 0.039245409010683005, 0.020162415761267267, 0.01213665955466936, 0.007844183075140749, 0.005622121219502382, 0.004360810639704754, 0.0036254609793401602, 0.003227933710655199,
            0.002979809740808725, 0.00282061844653736, 0.002690232723881576, 0.0026001170673960487, 0.002562044629569472, 0.002519477019181742, 0.0024810265257135737, 0.0024751883796675835, 0.002454869183936775, 0.0024361135014903867]

validation = [1.5430280752968335, 0.04655044942169049, 0.012567202578954368, 0.0077499105044510595, 0.0063863054069094064, 0.005939421700402758, 0.005828289894090714, 0.005798761745951018, 0.0056109485793223056, 0.005294173175878378003063,
              0.0043668021247888975, 0.003656957498459, 0.003063497967612522, 0.0027821576665144113, 0.0026713620408415515, 0.0025840598467841733, 0.0025103013341010298, 0.0024399829923108392, 0.002471129431470709, 0.002465181064094512]

# testing = [5.415847422146913e-05, 0.0001799084962160745, 0.00012496513331052106, 3.3418461021903966e-05, 5.803669668658615e-05, 7.11769560456769e-05, 5.1253623047968577e-05, 3.057536556409826e-05, 8.154664762583395e-05, 6.88539071565906e-05, 0.00015984170014838266, 2.3100710970014838266e-05, 2.31007109659842e-05, 4.537010031386033e-05, 6.914245959564551e-05, 3.0990266852907955e-05, 9.122587714111203e-05, 9.786197844167606e-05, 7.53726788046438e-05, 0.00013252855742917078, 2.62648697540247e-05, 9.429480047193089e-05, 0.00011681849942597676, .00017475099500141087, 0.00011681849942597676, 3.6376818720304455e-05, 1.6452405778784256e-05,
#            3.913159494655762e-05, 6.28941638558854e-05, 0.00010599617723796918, 4.952426146661424e-05, 5.489728154190495e-05, 9.58875583013903e-05, 5.64675384614273615e-05, 2.5577170445388637e-05, 2.0641824614273615e-05, 0.00024242847411773158, 8.442983089539559e-05, 5.7502858116307544e-05, 5.759130577191295e-05, 5.313623558317656e-05, 8.412879026856901e-05, 4.912982254739517e-05, 4.686647225871444e-05, 6.02014760247799e-05, 4.612201254840268e-05, 5.0054910475723486e-05, 0.00024758900710042354, 6.020147602477995e-05, 8.31574621059854e-05, 6.67628064644545e-05, 5.551180399717944e-05, 4.875871274583309e-05]

testing = [0.002635666331502567, 0.0006718727168709524, 0.0006468491166104587, 0.0001714721383565762, 9.255395524624847e-05, 0.00031147643248786495, 5.749046585756538e-05, 0.0001388710054274685, 0.0003599316362933654, 1.545264291455641e-05,
           8.774920174885053e-05, 3.284104028589853e-05, 0.0001223320624005361, 3.1345158990091626e-05, 2.2936915831972557e-05, 0.0002432838431957142, 0.00015230174888920448, 0.00013863267381558674, 0.0001530265433510779, 2.9932076746271357e-05]
# validation = [0.7374038901210223, 0.008893552914802118, 0.0046550840333380245, 0.003084949647773892, 0.003730480973430531, 0.00496539525397729, 0.0050440102550918416, 0.003969783880514906, 0.0037124270041537575, 0.004061127447245052, 0.005878954875123363, 0.004913296109927033, 0.00389033004581417, 0.0030911856854451774, 0.0029307960119851584, 0.003019430961608251, 0.0029392058218184773, 0.0029868542040621436, 0.0029836472139431916, 0.00301880085816679, 0.0031837818870674574, 0.0030947892064914348, 0.0031243802924130894, 0.002984842018522331, 0.0030007386591788462, 0.0032367987462899868, 0.003176128189638897, 0.0030994844983072284, 0.0034450164671123618, 0.003158501194816917, 0.0031833037439718, 0.0030983978763303643,
#               0.003047004485079479, 0.0029082039264902364, 0.0027740186901869966, 0.002819591489228637, 0.0029643557002672813, 0.003046606125526507, 0.003014702834266126, 0.003016446958189184, 0.00294455651372244, 0.002859409639166066, 0.0028427622429499358, 0.0027875584312886162, 0.0028918570247470207, 0.0029865745838098833, 0.0028688339644107786, 0.0028653361156152656, 0.002955816756167911, 0.00302107286171505]

# 1000 test items
training = [1.6126595001358497, 0.23406680308721187, 0.055971006086261155, 0.023817830550972263, 0.013893740949468434, 0.009046984054871272, 0.00636741593542016, 0.004872905362170972, 0.0039546593960332055, 0.0034225763464663613, 0.003090137565305725, 0.0028933553646758, 0.002729911622243636, 0.0026567275424671517, 0.0025708604830857328, 0.00254697464399247, 0.0025058393836867084, 0.002468053028970145, 0.0024622524326071275, 0.002443208118816589,
            0.0024276361259864174, 0.0024226075557292437, 0.0023988948644180336, 0.0024054398037521157, 0.0023813125096828337, 0.002358543083344724, 0.0023451927932114304, 0.002321677401342338, 0.0023075043103138178, 0.002281922752563196, 0.002258918967056715, 0.002230655930702192, 0.0021992028429639694, 0.0021870825701868963, 0.0021757639978907503, 0.002144060096606778, 0.002127548589829032, 0.0021186309712288055, 0.0021131633007976038, 0.002072151447770491]
testing = [0.0016532859731371353, 0.0011092502011940937, 0.00017270018457608, 7.861419290023295e-05, 0.0001869831955775378, 0.000606873765649041, 0.00030012036281249085, 0.00011722687637161005, 4.300229672895603e-05, 0.00010124378013134178, 7.00568790517134e-05, 0.00019930442791433122, 5.1691529624592314e-05, 2.6931097285363017e-05, 8.283936590832786e-05, 0.00014229531443731716, 2.3115177402645323e-05, 2.779839964499613e-05, 1.6607193004399008e-05, 0.0001678574915262473,
           0.0001158489091974873, 7.511598884916675e-05, 4.680708408211636e-05, 0.0003112410548271735, 5.665356071226477e-05, 0.00014117321531397943, 2.5381137389053093e-05, 1.4873069486222331e-05, 3.7168986728608754e-05, 2.0677512293043614e-05, 2.583994382485618e-05, 3.5226760743879354e-05, 0.0002370980074877311, 0.0001387385237818195, 3.591546935239849e-05, 5.794544677736838e-05, 4.218024113229429e-05, 0.0002750011243772324, 6.805478628440801e-05, 0.00011541698946179029]
validation = [1.6554995334989335, 0.08021327278988676, 0.0191116330534057, 0.006742680533023518, 0.0060590165498182556, 0.006622508768052731, 0.007117070728425236, 0.007388989605302322, 0.007111732723629387, 0.006079975242510907, 0.004947957576714508, 0.004027834143491463, 0.0031571117741251023, 0.0028500672879352893, 0.0027052958855480745, 0.0027001786181392153, 0.0025911346569559425, 0.002532766798047544, 0.0025637865057230283, 0.002532683858937441,
              0.002540990913035215, 0.002648879522470951, 0.002702648872789053, 0.0026816282352721977, 0.0026894787585401182, 0.002671395453149898, 0.0028113275675559547, 0.0028109681289143216, 0.0026954952956519482, 0.0026723208964972763, 0.0028126507730327106, 0.002874728833454195, 0.0029639344225039803, 0.0029250471406266805, 0.0028783838770405717, 0.0029076454865450212, 0.0029755579168411765, 0.0030107802013135555, 0.002945951708765494, 0.0028694517074799543]

# 1000 test items 150 epochs
validation = [1.542635582447612, 0.058822490556138265, 0.02085689223764426, 0.010237649096266994, 0.006955951405427917, 0.006538819577513887, 0.006882337639478662, 0.0069703117488286856, 0.006274310093523217, 0.005289316179722473, 0.004420336370921359, 0.0035813952301677284, 0.0031126125858639054, 0.0028735582338321936, 0.0028209216264327174, 0.002854758565912707, 0.002934767156632189, 0.0031396455478712904, 0.0032690530899615075, 0.0032794147354014884, 0.0034835920523947727, 0.0035360180852372944, 0.003829573355190516, 0.0036472083310753324, 0.003512495968360274, 0.003377977510950557, 0.0033596642235755045, 0.0033624432264385846, 0.0035754390756205607, 0.003662764519097746, 0.003788813484748824, 0.0036960397261772754, 0.003708360760072258, 0.003569598064231397, 0.0034437275729264152, 0.0035813181250511274, 0.0035095017405173817, 0.0034692627528516403, 0.003523263365039206, 0.003453526270224879, 0.003335760511904181, 0.0034382849401814416, 0.003354595837205495, 0.003501521980852116, 0.0034995652562349656, 0.0033496689587542675, 0.0033880726482293016, 0.003240746555028593, 0.0030368774364961312, 0.0030393501425546353, 0.003234880186990258, 0.003224850767642653, 0.0031162927087781474, 0.003122181469245764, 0.003122564306269281, 0.003055245281065497, 0.0031339290516019546, 0.003045033757753972, 0.0031475481367258013, 0.0031517646402878735, 0.0029571949881656116, 0.0030187109721232027, 0.0029518558381142397, 0.002950527414732927, 0.0028680039243689955, 0.003042409273209969, 0.002934852678534074, 0.0027919985372921166, 0.002883386663401358, 0.002945219103868901, 0.0027099631832175576, 0.0027048464274186056, 0.0026856583243565673, 0.002612831095233654, 0.0026782955112561093, 0.00255716434437864, 0.002559906450069477, 0.0026007033564844316, 0.0026927093182617617, 0.00278998198914483, 0.0027889184511967627, 0.002737649068177668, 0.0027950452463259014, 0.002655588306361819, 0.002724668169024324, 0.0027337339522437013, 0.002835119410791203, 0.0028148260579544926, 0.002907784448551568, 0.002769600677625665, 0.002697732719990621, 0.00270091292278944, 0.0026687239850713643, 0.0026116198510192233, 0.00265272811685368, 0.0026748945956294864, 0.0026634442053961043, 0.0027051351807973276, 0.0026452708037279305, 0.0026657967244891802, 0.0026504672590384245, 0.002639292540808309, 0.002605170260858494, 0.002604138810848844, 0.00259412044781111,
              0.0025632155691217053, 0.002551629701440396, 0.0025942774600887027, 0.0025459478322393224, 0.002577283818154197, 0.002580297138741027, 0.002567883679091362, 0.0026115181682179445, 0.0025955145956651367, 0.002460982494341634, 0.0024264830878870333, 0.0024816380575187528, 0.002540453805269938, 0.0024917797881845016, 0.0024128154012166224, 0.002465062944462615, 0.0024764951760802723, 0.00241908521260336, 0.002400000594834657, 0.0023588122134265343, 0.0023730183024475806, 0.002336342534310569, 0.002351946408281266, 0.002346760916731308, 0.002350439196074733, 0.002382104201327401, 0.002458550793924946, 0.002476848099255391, 0.0024044216860937655, 0.0024691507963197643, 0.002480634407477156, 0.0024311551090323547, 0.0024057561639567685, 0.002346498150986556, 0.0023252678358581472, 0.002353721325877948, 0.002326488477720768, 0.00234758863124291, 0.0023850059376495595, 0.0024096709262073366, 0.0023860183641342533, 0.002374363827392529, 0.0023693751789225673, 0.0023952302240546554, 0.0024084765392108445]

training = [1.594810920734169, 0.12553062654316, 0.042433011699578485, 0.02145763404574798, 0.012658518556048074, 0.008247655791370575, 0.005843038627964527, 0.004513317640926067, 0.0037158022531880155, 0.0032340784643363155, 0.002962260303555179, 0.002755412950067866, 0.0026471996596631182, 0.0025579394357898183, 0.0024662196865760898, 0.0024175530834252457, 0.0023890643452515624, 0.002332985799595592, 0.0023090162756264437, 0.0022666062885612496, 0.002231937775981584, 0.002220326408062787, 0.0022096753033068782, 0.002211110664164594, 0.0021904554474150026, 0.0021856230029056603, 0.002187902904507316, 0.0021672052463166426, 0.0021609809942642077, 0.002152784172427672, 0.002142852436748593, 0.0021314419073104524, 0.0021271335997219976, 0.0021148041028944613, 0.002114915189166036, 0.0021080651349122464, 0.0021098957475955003, 0.0020998843258745225, 0.0020908892589164303, 0.0020909404427074596, 0.0020811352897439146, 0.002081662037258789, 0.0020810526851159344, 0.002069184840691419, 0.0020662192250063822, 0.002067919091910179, 0.0020568709126797514, 0.0020502903555375054, 0.0020391922792484954, 0.0020454412159324905, 0.0020415589583024038, 0.002045503368116092, 0.0020384816734417906, 0.0020327818088910553, 0.002023592471141026, 0.0020299167781230804, 0.002029204090922867, 0.0020087427931888883, 0.002016027234067898, 0.002015485271966304, 0.0020090262849818664, 0.002010085109709825, 0.002009124078561802, 0.0020078883738288925, 0.0020075486457286503, 0.002031805533923999, 0.002030218369719583, 0.002032534044435777, 0.002008692048817407, 0.002010186096137023, 0.002012632713945258, 0.0020046105510448165, 0.002005984489384835, 0.0020107902063406374, 0.001993125852862849,
            0.001989023965956348, 0.002000175051624992, 0.0020055859801422033, 0.0019880727873066947, 0.0019837567591208635, 0.001985649175051887, 0.0019923060571512183, 0.001976996176450589, 0.001991796267352662, 0.0019612630705899254, 0.0019691874578029282, 0.00195086060141603, 0.001964552896288345, 0.001954926371914379, 0.0019441844885520127, 0.0019634576438300787, 0.0019656800291728747, 0.0019557176963907233, 0.001958078762389464, 0.001959104393177561, 0.0019529269776959622, 0.0019577413061125618, 0.0019520048457700794, 0.0019482423643350777, 0.001945023134055689, 0.0019520192553184428, 0.0019393175303416789, 0.0019450353033080155, 0.0019329985008922424, 0.0019478448747444151, 0.0019232746006175177, 0.0019169887147067902, 0.0019225569971040273, 0.0019326190403802272, 0.0019277583931011553, 0.001926830317291649, 0.001924748788297774, 0.0019060162342170626, 0.001926210633969061, 0.0019266791080536374, 0.0019183838486600898, 0.0019203466900258748, 0.0019095177790840138, 0.0019091322391710337, 0.001905830528440082, 0.0019093565405825122, 0.0019104620051823447, 0.0019062525560133794, 0.0019158370555294494, 0.0019044236990201377, 0.00191823734837444, 0.0018906280310464767, 0.0018915104128203863, 0.001900877984795117, 0.0019064395816295774, 0.0019077266182755761, 0.0019153324820807816, 0.0019036393459313061, 0.00190989963940157, 0.0019030570383545451, 0.001892628539699807, 0.0019054723746179398, 0.0018924386450989788, 0.0019113060380203598, 0.0019010136933082166, 0.0019172762736182991, 0.0018975053339736407, 0.0018976201448986322, 0.0018953441835963083, 0.0018935420898878825, 0.0018984007502246573, 0.0018998077923586456, 0.001896727114383056, 0.0019073292876439305, 0.0018977011200776216]
testing = [0.0023311486458717622, 0.0014120932156907932, 0.0003350208432618667, 8.18268693424416e-05, 6.8586857500392e-05, 0.00017191016358042598, 0.00029873345485483004, 0.00017450832544826993, 0.000465563980092358, 0.0001698770295923906, 8.316310950510098e-05, 0.00016573916496994914, 5.505340696688727e-05, 9.756757478500818e-06, 9.129770490478083e-05, 3.945611140195519e-05, 3.846619737956252e-05, 2.1766920536041014e-05, 8.60885549337265e-05, 3.9738525377020966e-05, 0.00017269997408995438, 6.225443502217531e-05, 3.445513521645683e-05, 3.883043573763328e-05, 0.00024969558782515045, 0.00016902546287904851, 7.312923053663031e-05, 0.0002347041776141967, 1.156271865310461e-05, 3.958332265423044e-05, 3.5725247527577436e-05, 5.935019197923743e-05, 0.00015106610172037162, 0.00040613912545670234, 5.8954162504075624e-05, 0.0006463937298751097, 4.654188075348233e-05, 8.248401010160502e-05, 0.00036254152247985167, 4.343998585353622e-05, 6.340894372413633e-05, 0.0002336420026196347, 1.8831129271448136e-05, 0.0001647808099977904, 9.318762070116661e-05, 0.00013688320597582933,
           2.8362613760870297e-05, 6.850172412204244e-05, 2.407451806653193e-05, 0.0002947309787746751, 0.00020667115001699602, 5.931564338450058e-05, 7.63103866366057e-05, 7.499113404957396e-05, 5.0588491899970556e-05, 1.796485936142309e-05, 0.0002376455045760786, 0.00038418174226318195, 0.00015423220220844264, 3.801744397914009e-05, 0.0002265452827377101, 5.9857179153089634e-05, 0.00015816377281919255, 8.628810773650887e-05, 0.00012024061055881488, 6.106416858743868e-05, 0.00017980773864830494, 3.8364058724817e-05, 6.32137206342474e-05, 8.228951317458553e-05, 0.00017440070985079914, 1.5683060554077363e-05, 1.643076036878535e-05, 9.828643175952317e-05, 4.649426768033974e-05, 5.5268675484369936e-05, 5.7314473682849205e-05, 1.8795358881238846e-05, 3.5109940468893286e-05, 0.00020870644966869154, 5.131104502055998e-05, 0.00013821830619671746, 5.6991220185420634e-05, 2.6962798459354e-05, 1.5396838451621842e-05, 4.9655461779599034e-05, 2.3817234772960488e-05, 6.108772441092337e-05, 2.363287082994174e-05, 0.0002881444247392612, 0.0001747464021541077, 1.5516383889528695e-05, 8.825409244117269e-05, 2.4802300449235424e-05, 6.361422848446062e-05, 5.3086522514416696e-05, 3.787160871072605e-05, 0.0003318040179562968, 6.651570314205072e-05, 4.639321848403686e-05, 6.139859381808293e-05, 5.0902558363923086e-05, 2.3535227662145508e-05, 0.0001616330352574395, 0.00011095534888645548, 0.00010047001884583402, 2.597612480722576e-05, 7.236780721561962e-05, 3.498428038118892e-05, 4.658192246432243e-05, 5.9849485421287634e-05, 4.346254229023258e-05, 0.00015139841012094352, 3.5621885124822594e-05, 0.00010327191290922895, 2.4938380917484577e-05, 2.184732088417106e-05, 3.596503221938825e-05, 3.5831656956959586e-05, 9.286182227451408e-05, 0.00012977015063167667, 2.5856857076840087e-05, 0.000254703081288333, 3.6738321930707596e-05, 4.729681976267042e-05, 0.00014588781849066964, 0.0001225829906365984, 8.290006515960121e-05, 8.824010224459226e-05, 4.9473371095944717e-05, 7.363440213947052e-05, 4.167696310122633e-05, 6.419917316860824e-05, 0.00016620961220359607, 0.0002318526508408676, 5.1482472423955444e-05, 1.5709131570283458e-05, 0.0001746831420389343, 4.1810169073764444e-05, 2.7020298580654855e-05, 9.152752492222192e-05, 0.00013951111499920004, 3.0764702630621754e-05, 3.767091509982252e-05, 0.00012800734380532684, 4.97621037324741e-05, 5.5117406327018975e-05, 0.0001524409694900497, 5.027503133635999e-05, 2.2807932491062018e-05]


sns.set(style='whitegrid', palette='muted', font_scale=1.5)
# plt.plot(validation[5:], label='validation loss', color='orange')
plt.plot(testing[5:], label='testing loss', color='blue')
# plt.plot(training[5:], label='training loss', color='green')
plt.title('Sliding window validation loss 50 epochs')
plt.xlabel('epoch')
plt.ylabel('Loss')
plt.legend(loc='best')
plt.show()
print(testing[30])
print(testing[31])
print(testing[32])
print(testing[33])
